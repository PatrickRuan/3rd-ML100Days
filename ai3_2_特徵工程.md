D22 特徵工程簡介_
介紹機器學習完整步驟中，特徵工程的位置以及流程架構

D23 數值型特徵 - 去除偏態_
數值型特徵若分布明顯偏一邊，則需去除偏態以消除預測的偏差

D24 類別型特徵 - 基礎處理
介紹類別型特徵最基礎的作法 : 標籤編碼與獨熱編碼

D25 類別型特徵 - 均值編碼
類別型特徵最重要的編碼 : 均值編碼，將標籤以目標均值取代

D26類別型特徵 - 其他進階處理
類別型特徵的其他常見編碼 : 計數編碼對應出現頻率相關的特徵，雜湊編碼對應眾多類別而無法排序的特徵

D27 時間型特徵
時間型特徵可抽取出多個子特徵，或周期化，或取出連續時段內的次數

D28 特徵組合 - 數值與數值組合
特徵組合的基礎 : 以四則運算的各種方式，組合成更具預測力的特徵

D29 特徵組合 - 類別與數值組合
類別型對數值型特徵可以做群聚編碼，與目標均值編碼類似，但用途不同🏍

D30 特徵選擇
介紹常見的幾種特徵篩選方式

D31 特徵評估
介紹並比較兩種重要的特徵評估方式，協助檢測特徵的重要性

D32 分類型特徵優化 - 葉編碼
葉編碼 : 適用於分類問題的樹狀預估模型改良














均值編碼

    data = pd.concat([df[:train_num], train_Y], axis=1)
    for c in df.columns:
        mean_df = data.groupby([c])['Survived'].mean().reset_index()
        mean_df.columns = [c, f'{c}_mean']
        data = pd.merge(data, mean_df, on=c, how='left')
        data = data.drop([c] , axis=1)
    data = data.drop(['Survived'] , axis=1)
    estimator = LogisticRegression()
    start = time.time()
    print(f'shape : {X.shape}')
    print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')
    print(f'time : {time.time() - start} sec')
    
    這一段 code 因為 ticket_mean, name_mean 項目太多，每一個都被標籤了 target, 自然是 overfitting.
    留意的是，我們的 cross_val_score 用在 training data，所以效果都是好的。(?)
    還有, meanvalueencoding 算不算洩漏 target???
