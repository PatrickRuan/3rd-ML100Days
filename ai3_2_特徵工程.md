D22 特徵工程簡介_
介紹機器學習完整步驟中，特徵工程的位置以及流程架構

D23 數值型特徵 - 去除偏態_
數值型特徵若分布明顯偏一邊，則需去除偏態以消除預測的偏差

D24 類別型特徵 - 基礎處理
介紹類別型特徵最基礎的作法 : 標籤編碼與獨熱編碼

D25 類別型特徵 - 均值編碼
類別型特徵最重要的編碼 : 均值編碼，將標籤以目標均值取代

D26類別型特徵 - 其他進階處理
類別型特徵的其他常見編碼 : 計數編碼對應出現頻率相關的特徵，雜湊編碼對應眾多類別而無法排序的特徵

D27 時間型特徵
時間型特徵可抽取出多個子特徵，或周期化，或取出連續時段內的次數

D28 特徵組合 - 數值與數值組合
特徵組合的基礎 : 以四則運算的各種方式，組合成更具預測力的特徵

D29 特徵組合 - 類別與數值組合
類別型對數值型特徵可以做群聚編碼，與目標均值編碼類似，但用途不同🏍

D30 特徵選擇
介紹常見的幾種特徵篩選方式

D31 特徵評估
介紹並比較兩種重要的特徵評估方式，協助檢測特徵的重要性

D32 分類型特徵優化 - 葉編碼
葉編碼 : 適用於分類問題的樹狀預估模型改良


D27, D28 是將時間資訊抽出來，
    
    有年，月，日，時，分，秒。還可以利用其他方法將 woy, moy 等抽出。對於 weekday 的順序利用 cos 來週期，#ofweek 也是 cos, # of month 也是 cos.  記住操作係數是周期的一半，因為 cos週期有 2.
    還有，求距離用歐式距離求很方便，但是我們會利用緯度 cos.(緯度 mean) 修正....
    
D29, 特整組合，

    是 groupby(['1'])['2'].mean().reset_index() 的延伸，去加 mode(.apply(lambda x:x.mode()[0])), median, max
    記得將這些用 pd.merge(mean, mode, on=['1'], how='left) 一一縫起來。最後跟 df 縫起來，再 drop ['1'] 甚至 drop ['2']
    
D30 特徵選擇，

    sns.heapmap, 或直接用 np.corr, 然後去查看 corr >0.1 or corr <-0.1 ==> 去除共線性...
    也用 Lasso 去除一些 0 係數，L1_Reg.fit ==>   L1_Reg.coef_, mask coef==0













均值編碼

    data = pd.concat([df[:train_num], train_Y], axis=1)
    for c in df.columns:
        mean_df = data.groupby([c])['Survived'].mean().reset_index()
        mean_df.columns = [c, f'{c}_mean']
        data = pd.merge(data, mean_df, on=c, how='left')
        data = data.drop([c] , axis=1)
    data = data.drop(['Survived'] , axis=1)
    estimator = LogisticRegression()
    start = time.time()
    print(f'shape : {X.shape}')
    print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')
    print(f'time : {time.time() - start} sec')
    
    這一段 code 因為 ticket_mean, name_mean 項目太多，每一個都被標籤了 target, 自然是 overfitting.
    留意的是，我們的 cross_val_score 用在 training data，所以效果都是好的。(?)
    還有, meanvalueencoding 算不算洩漏 target???


D26  # 觀察欄位相異值數量
    
    df.select_dtypes(include=["object"]).apply(pd.Series.nunique)
    
    count_df = df.groupby(['Cabin'])['Name'].agg({'Cabin_Count':'size'}).reset_index()
    df = pd.merge(df, count_df, on=['Cabin'], how='left')
    count_df.sort_values(by=['Cabin_Count'], ascending=False).head(10)
    df_temp['Cabin_Hash'] = df['Cabin'].map(lambda x:hash(x) % 10)
    
    
    
D27 #

    df['pickup_datetime'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S UTC'))
    df['pickup_year'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%Y')).astype('int64')
    df['pickup_month'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%m')).astype('int64')
    df['pickup_day'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%d')).astype('int64')
    df['pickup_hour'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%H')).astype('int64')
    df['pickup_minute'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%M')).astype('int64')
    df['pickup_second'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%S')).astype('int64')
